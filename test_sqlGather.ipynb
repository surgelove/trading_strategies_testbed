{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d79015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def connect_to_database(db_path):\n",
    "    \"\"\"\n",
    "    Connect to the specified database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(db_path):\n",
    "            print(f\"‚ùå Database file not found: {db_path}\")\n",
    "            return None\n",
    "        \n",
    "        conn = sqlite3.connect(db_path)\n",
    "        print(f\"‚úÖ Successfully connected to database: {db_path}\")\n",
    "        return conn\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"‚ùå Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_database_structure(conn):\n",
    "    \"\"\"\n",
    "    Analyze the database to find tables with date and buy columns\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        print(f\"üìä Found {len(tables)} table(s) in the database\")\n",
    "        \n",
    "        suitable_tables = {}\n",
    "        \n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            print(f\"\\nüî∏ Analyzing table: {table_name}\")\n",
    "            \n",
    "            # Get column info\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns = cursor.fetchall()\n",
    "            column_names = [col[1].lower() for col in columns]\n",
    "            original_columns = [col[1] for col in columns]\n",
    "            \n",
    "            # Look for date columns\n",
    "            date_columns = [col for col in original_columns if any(keyword in col.lower() \n",
    "                           for keyword in ['date', 'time', 'timestamp', 'day'])]\n",
    "            \n",
    "            # Look for buy columns\n",
    "            buy_columns = [col for col in original_columns if any(keyword in col.lower() \n",
    "                          for keyword in ['buy', 'purchase', 'bid'])]\n",
    "            \n",
    "            # Look for instrument columns\n",
    "            instrument_columns = [col for col in original_columns if any(keyword in col.lower() \n",
    "                                 for keyword in ['symbol', 'instrument', 'ticker', 'asset', 'code'])]\n",
    "            \n",
    "            print(f\"   Date columns found: {date_columns}\")\n",
    "            print(f\"   Buy columns found: {buy_columns}\")\n",
    "            print(f\"   Instrument columns found: {instrument_columns}\")\n",
    "            \n",
    "            if date_columns and buy_columns and instrument_columns:\n",
    "                # Get row count\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "                row_count = cursor.fetchone()[0]\n",
    "                \n",
    "                suitable_tables[table_name] = {\n",
    "                    'date_columns': date_columns,\n",
    "                    'buy_columns': buy_columns,\n",
    "                    'instrument_columns': instrument_columns,\n",
    "                    'row_count': row_count,\n",
    "                    'all_columns': original_columns\n",
    "                }\n",
    "                print(f\"   ‚úÖ Suitable table with {row_count:,} rows\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  Missing required columns\")\n",
    "        \n",
    "        return suitable_tables\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"‚ùå Error analyzing database: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_instruments_and_create_csvs(conn, suitable_tables):\n",
    "    \"\"\"\n",
    "    Extract data for each instrument and create CSV files\n",
    "    \"\"\"\n",
    "    if not suitable_tables:\n",
    "        print(\"‚ùå No suitable tables found\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = f\"instrument_csvs_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"üìÅ Created output directory: {output_dir}\")\n",
    "    \n",
    "    total_files_created = 0\n",
    "    \n",
    "    for table_name, table_info in suitable_tables.items():\n",
    "        print(f\"\\nüìä Processing table: {table_name}\")\n",
    "        \n",
    "        # Use first available columns\n",
    "        date_col = table_info['date_columns'][0]\n",
    "        buy_col = table_info['buy_columns'][0]\n",
    "        instrument_col = table_info['instrument_columns'][0]\n",
    "        \n",
    "        print(f\"   Using columns: {instrument_col} (instrument), {date_col} (date), {buy_col} (buy)\")\n",
    "\n",
    "        try:\n",
    "            # Get unique instruments\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(f\"SELECT DISTINCT {instrument_col} FROM {table_name} WHERE {instrument_col} IS NOT NULL ORDER BY {instrument_col};\")\n",
    "            instruments = cursor.fetchall()\n",
    "            \n",
    "            print(f\"   Found {len(instruments)} unique instruments\")\n",
    "            \n",
    "            for instrument_tuple in instruments:\n",
    "                instrument = instrument_tuple[0]\n",
    "                if instrument is None:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Query data for this instrument\n",
    "                    query = f\"\"\"\n",
    "                    SELECT {date_col} as date, {buy_col} as buy\n",
    "                    FROM {table_name}\n",
    "                    WHERE {instrument_col} = ?\n",
    "                    AND {date_col} IS NOT NULL\n",
    "                    AND {buy_col} IS NOT NULL\n",
    "                    ORDER BY {date_col}\n",
    "                    LIMIT 2\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    df = pd.read_sql_query(query, conn, params=[instrument])\n",
    "\n",
    "                    print(instrument)\n",
    "                    print(df)\n",
    "                    print('_'*20)\n",
    "                    \n",
    "                    \n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error processing {instrument}: {e}\")\n",
    "            \n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"‚ùå Error processing table {table_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Summary:\")\n",
    "    print(f\"   Total CSV files created: {total_files_created}\")\n",
    "    print(f\"   Output directory: {output_dir}\")\n",
    "    \n",
    "    # List some of the created files\n",
    "    if total_files_created > 0:\n",
    "        files = os.listdir(output_dir)\n",
    "        print(f\"   Sample files created:\")\n",
    "        for i, file in enumerate(files[:10]):  # Show first 10 files\n",
    "            file_path = os.path.join(output_dir, file)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"     ‚Ä¢ {file} ({file_size} bytes)\")\n",
    "        \n",
    "        if len(files) > 10:\n",
    "            print(f\"     ... and {len(files) - 10} more files\")\n",
    "\n",
    "\n",
    "# Main execution\n",
    "db_path = \"aia_big.db\"\n",
    "\n",
    "# Connect to database\n",
    "conn = connect_to_database(db_path)\n",
    "\n",
    "if conn:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîç ANALYZING DATABASE STRUCTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Analyze database structure\n",
    "    suitable_tables = analyze_database_structure(conn)\n",
    "    \n",
    "    if suitable_tables:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üì• CREATING CSV FILES FOR EACH INSTRUMENT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Create CSV files for each instrument\n",
    "        get_instruments_and_create_csvs(conn, suitable_tables)\n",
    "        \n",
    "    \n",
    "    conn.close()\n",
    "    print(f\"\\n‚úÖ Database connection closed\")\n",
    "else:\n",
    "    print(\"‚ùå Could not connect to database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f49fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
