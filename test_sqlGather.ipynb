{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d79015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to database: aia_big.db\n",
      "\n",
      "============================================================\n",
      "üîç ANALYZING DATABASE STRUCTURE\n",
      "============================================================\n",
      "üìä Found 1 table(s) in the database\n",
      "\n",
      "üî∏ Analyzing table: gather\n",
      "   Date columns found: ['date']\n",
      "   Buy columns found: ['buy']\n",
      "   Instrument columns found: ['instrument']\n",
      "   ‚úÖ Suitable table with 54,754,326 rows\n",
      "\n",
      "============================================================\n",
      "üì• CREATING CSV FILES FOR EACH INSTRUMENT\n",
      "============================================================\n",
      "üìÅ Created output directory: instrument_csvs_20250626_083536\n",
      "\n",
      "üìä Processing table: gather\n",
      "   Using columns: instrument (instrument), date (date), buy (buy)\n",
      "   Found 123 unique instruments\n",
      "AU200_AUD\n",
      "                         date       buy\n",
      "0  2025-02-21 20:59:05.094028  8243.975\n",
      "1  2025-02-28 20:59:05.122735  8217.675\n",
      "____________________\n",
      "AUD_CAD\n",
      "                         date      buy\n",
      "0  2025-02-21 21:59:05.136159  0.90511\n",
      "1  2025-02-28 21:59:05.202375  0.89869\n",
      "____________________\n",
      "AUD_CHF\n",
      "                         date       buy\n",
      "0  2025-02-21 21:59:05.138682  0.571561\n",
      "1  2025-02-28 21:59:05.204018  0.561041\n",
      "____________________\n",
      "AUD_HKD\n",
      "                         date       buy\n",
      "0  2025-02-21 21:59:05.140598  4.943505\n",
      "1  2025-02-28 21:59:05.205809  4.833735\n",
      "____________________\n",
      "AUD_JPY\n",
      "                         date        buy\n",
      "0  2025-02-21 21:59:05.142387  94.982625\n",
      "1  2025-02-28 21:59:05.208626  93.570625\n",
      "____________________\n",
      "AUD_NZD\n",
      "                         date       buy\n",
      "0  2025-02-21 21:59:05.333374  1.107843\n",
      "1  2025-02-28 21:59:05.143037  1.109683\n",
      "____________________\n",
      "AUD_SGD\n",
      "                         date       buy\n",
      "0  2025-02-21 21:59:05.144836  0.851331\n",
      "1  2025-02-28 21:59:05.209314  0.840011\n",
      "____________________\n",
      "AUD_USD\n",
      "                         date      buy\n",
      "0  2025-02-21 21:59:05.146792  0.63610\n",
      "1  2025-02-28 21:59:05.210751  0.62137\n",
      "____________________\n",
      "BCO_USD\n",
      "                         date     buy\n",
      "0  2025-02-21 21:59:05.394676  74.456\n",
      "1  2025-02-28 21:59:05.306702  73.573\n",
      "____________________\n",
      "CAD_CHF\n",
      "                         date       buy\n",
      "0  2025-02-21 21:59:05.148816  0.631994\n",
      "1  2025-02-28 21:59:05.212171  0.624804\n",
      "____________________\n",
      "CAD_HKD\n",
      "                         date      buy\n",
      "0  2025-02-21 21:59:05.150986  5.46706\n",
      "1  2025-02-28 21:59:05.213452  5.38787\n",
      "____________________\n",
      "CAD_JPY\n",
      "                         date         buy\n",
      "0  2025-02-21 21:59:05.153140  105.011857\n",
      "1  2025-02-28 21:59:05.214710  104.171857\n",
      "____________________\n",
      "CAD_SGD\n",
      "                         date      buy\n",
      "0  2025-02-21 21:59:05.154518  0.94041\n",
      "1  2025-02-28 21:59:05.215938  0.93548\n",
      "____________________\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def connect_to_database(db_path):\n",
    "    \"\"\"\n",
    "    Connect to the specified database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(db_path):\n",
    "            print(f\"‚ùå Database file not found: {db_path}\")\n",
    "            return None\n",
    "        \n",
    "        conn = sqlite3.connect(db_path)\n",
    "        print(f\"‚úÖ Successfully connected to database: {db_path}\")\n",
    "        return conn\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"‚ùå Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_database_structure(conn):\n",
    "    \"\"\"\n",
    "    Analyze the database to find tables with date and buy columns\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        print(f\"üìä Found {len(tables)} table(s) in the database\")\n",
    "        \n",
    "        suitable_tables = {}\n",
    "        \n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            print(f\"\\nüî∏ Analyzing table: {table_name}\")\n",
    "            \n",
    "            # Get column info\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns = cursor.fetchall()\n",
    "            column_names = [col[1].lower() for col in columns]\n",
    "            original_columns = [col[1] for col in columns]\n",
    "            \n",
    "            # Look for date columns\n",
    "            date_columns = [col for col in original_columns if any(keyword in col.lower() \n",
    "                           for keyword in ['date', 'time', 'timestamp', 'day'])]\n",
    "            \n",
    "            # Look for buy columns\n",
    "            buy_columns = [col for col in original_columns if any(keyword in col.lower() \n",
    "                          for keyword in ['buy', 'purchase', 'bid'])]\n",
    "            \n",
    "            # Look for instrument columns\n",
    "            instrument_columns = [col for col in original_columns if any(keyword in col.lower() \n",
    "                                 for keyword in ['symbol', 'instrument', 'ticker', 'asset', 'code'])]\n",
    "            \n",
    "            print(f\"   Date columns found: {date_columns}\")\n",
    "            print(f\"   Buy columns found: {buy_columns}\")\n",
    "            print(f\"   Instrument columns found: {instrument_columns}\")\n",
    "            \n",
    "            if date_columns and buy_columns and instrument_columns:\n",
    "                # Get row count\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "                row_count = cursor.fetchone()[0]\n",
    "                \n",
    "                suitable_tables[table_name] = {\n",
    "                    'date_columns': date_columns,\n",
    "                    'buy_columns': buy_columns,\n",
    "                    'instrument_columns': instrument_columns,\n",
    "                    'row_count': row_count,\n",
    "                    'all_columns': original_columns\n",
    "                }\n",
    "                print(f\"   ‚úÖ Suitable table with {row_count:,} rows\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  Missing required columns\")\n",
    "        \n",
    "        return suitable_tables\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"‚ùå Error analyzing database: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_instruments_and_create_csvs(conn, suitable_tables):\n",
    "    \"\"\"\n",
    "    Extract data for each instrument and create CSV files\n",
    "    \"\"\"\n",
    "    if not suitable_tables:\n",
    "        print(\"‚ùå No suitable tables found\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = f\"instrument_csvs_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"üìÅ Created output directory: {output_dir}\")\n",
    "    \n",
    "    total_files_created = 0\n",
    "    \n",
    "    for table_name, table_info in suitable_tables.items():\n",
    "        print(f\"\\nüìä Processing table: {table_name}\")\n",
    "        \n",
    "        # Use first available columns\n",
    "        date_col = table_info['date_columns'][0]\n",
    "        buy_col = table_info['buy_columns'][0]\n",
    "        instrument_col = table_info['instrument_columns'][0]\n",
    "        \n",
    "        print(f\"   Using columns: {instrument_col} (instrument), {date_col} (date), {buy_col} (buy)\")\n",
    "\n",
    "        try:\n",
    "            # Get unique instruments\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(f\"SELECT DISTINCT {instrument_col} FROM {table_name} WHERE {instrument_col} IS NOT NULL ORDER BY {instrument_col};\")\n",
    "            instruments = cursor.fetchall()\n",
    "            \n",
    "            print(f\"   Found {len(instruments)} unique instruments\")\n",
    "            \n",
    "            for instrument_tuple in instruments:\n",
    "                instrument = instrument_tuple[0]\n",
    "                if instrument is None:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Query data for this instrument\n",
    "                    query = f\"\"\"\n",
    "                    SELECT {date_col} as date, {buy_col} as buy\n",
    "                    FROM {table_name}\n",
    "                    WHERE {instrument_col} = ?\n",
    "                    AND {date_col} IS NOT NULL\n",
    "                    AND {buy_col} IS NOT NULL\n",
    "                    ORDER BY {date_col}\n",
    "                    LIMIT 2\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    df = pd.read_sql_query(query, conn, params=[instrument])\n",
    "\n",
    "                    print(instrument)\n",
    "                    print(df)\n",
    "                    print('_'*20)\n",
    "                    \n",
    "                    \n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error processing {instrument}: {e}\")\n",
    "            \n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"‚ùå Error processing table {table_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Summary:\")\n",
    "    print(f\"   Total CSV files created: {total_files_created}\")\n",
    "    print(f\"   Output directory: {output_dir}\")\n",
    "    \n",
    "    # List some of the created files\n",
    "    if total_files_created > 0:\n",
    "        files = os.listdir(output_dir)\n",
    "        print(f\"   Sample files created:\")\n",
    "        for i, file in enumerate(files[:10]):  # Show first 10 files\n",
    "            file_path = os.path.join(output_dir, file)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"     ‚Ä¢ {file} ({file_size} bytes)\")\n",
    "        \n",
    "        if len(files) > 10:\n",
    "            print(f\"     ... and {len(files) - 10} more files\")\n",
    "\n",
    "\n",
    "# Main execution\n",
    "db_path = \"aia_big.db\"\n",
    "\n",
    "# Connect to database\n",
    "conn = connect_to_database(db_path)\n",
    "\n",
    "if conn:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîç ANALYZING DATABASE STRUCTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Analyze database structure\n",
    "    suitable_tables = analyze_database_structure(conn)\n",
    "    \n",
    "    if suitable_tables:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üì• CREATING CSV FILES FOR EACH INSTRUMENT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Create CSV files for each instrument\n",
    "        get_instruments_and_create_csvs(conn, suitable_tables)\n",
    "        \n",
    "    \n",
    "    conn.close()\n",
    "    print(f\"\\n‚úÖ Database connection closed\")\n",
    "else:\n",
    "    print(\"‚ùå Could not connect to database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0735f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
